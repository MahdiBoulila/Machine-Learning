{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J40R6z4GohW"
      },
      "source": [
        "# Transfer Learning with AutoEncoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLzPRPHaGohb"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib as plt\n",
        "import pandas as pd\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS5dmQHOGohd",
        "outputId": "f3288d96-5352-4168-dce4-4c5c82d64eab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZdA9LHNGohf"
      },
      "outputs": [],
      "source": [
        "#Testing the model that I am willing to use later for benchmarking\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY1r4OEMGohf",
        "outputId": "d79ddbb6-7f90-4045-a286-47dd51403c33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 1.6352 - accuracy: 0.5029 - val_loss: 0.8810 - val_accuracy: 0.7198\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8354 - accuracy: 0.7261 - val_loss: 0.7088 - val_accuracy: 0.7626\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.6961 - accuracy: 0.7694 - val_loss: 0.6324 - val_accuracy: 0.7862\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.6284 - accuracy: 0.7932 - val_loss: 0.5889 - val_accuracy: 0.8022\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5895 - accuracy: 0.8037 - val_loss: 0.5598 - val_accuracy: 0.8138\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5655 - accuracy: 0.8139 - val_loss: 0.5402 - val_accuracy: 0.8196\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5363 - accuracy: 0.8205 - val_loss: 0.5188 - val_accuracy: 0.8252\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5211 - accuracy: 0.8260 - val_loss: 0.5061 - val_accuracy: 0.8274\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5091 - accuracy: 0.8270 - val_loss: 0.4947 - val_accuracy: 0.8260\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4894 - accuracy: 0.8351 - val_loss: 0.4836 - val_accuracy: 0.8302\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6rYrj2cGohg",
        "outputId": "42b39853-e79f-44ea-afd4-5e4e19e650de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'loss': [1.2813036441802979,\n",
              "  0.7952855825424194,\n",
              "  0.6814340353012085,\n",
              "  0.6215713620185852,\n",
              "  0.582679271697998,\n",
              "  0.5547453761100769,\n",
              "  0.5337578654289246,\n",
              "  0.5172617435455322,\n",
              "  0.5036124587059021,\n",
              "  0.4920738935470581],\n",
              " 'accuracy': [0.6225273013114929,\n",
              "  0.7368545532226562,\n",
              "  0.7721090912818909,\n",
              "  0.7947636246681213,\n",
              "  0.8079817891120911,\n",
              "  0.8166727423667908,\n",
              "  0.8218363523483276,\n",
              "  0.8268908858299255,\n",
              "  0.8300363421440125,\n",
              "  0.833690881729126],\n",
              " 'val_loss': [0.8809624314308167,\n",
              "  0.7087973356246948,\n",
              "  0.6324403285980225,\n",
              "  0.5888940691947937,\n",
              "  0.55977463722229,\n",
              "  0.5402117967605591,\n",
              "  0.5187808871269226,\n",
              "  0.5060600638389587,\n",
              "  0.4946977198123932,\n",
              "  0.48364824056625366],\n",
              " 'val_accuracy': [0.7197999954223633,\n",
              "  0.7626000046730042,\n",
              "  0.7861999869346619,\n",
              "  0.8022000193595886,\n",
              "  0.8137999773025513,\n",
              "  0.819599986076355,\n",
              "  0.8252000212669373,\n",
              "  0.8274000287055969,\n",
              "  0.8259999752044678,\n",
              "  0.8302000164985657]}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Oe42cEbGohg",
        "outputId": "fa381715-5d5c-44e3-b611-6068a0397c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 2s 407ms/step - loss: 2.2749 - accuracy: 0.0890 - val_loss: 2.3266 - val_accuracy: 0.1042\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 2.2395 - accuracy: 0.1200 - val_loss: 2.3043 - val_accuracy: 0.1138\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 2.2564 - accuracy: 0.1332 - val_loss: 2.2941 - val_accuracy: 0.1276\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 2.1959 - accuracy: 0.2208 - val_loss: 2.2745 - val_accuracy: 0.1432\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 2.1879 - accuracy: 0.2062 - val_loss: 2.2592 - val_accuracy: 0.1516\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 2.1881 - accuracy: 0.1977 - val_loss: 2.2460 - val_accuracy: 0.1626\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 196ms/step - loss: 2.1688 - accuracy: 0.2217 - val_loss: 2.2376 - val_accuracy: 0.1682\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 2.1421 - accuracy: 0.1996 - val_loss: 2.2255 - val_accuracy: 0.1744\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 2.1103 - accuracy: 0.2154 - val_loss: 2.2085 - val_accuracy: 0.1920\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 161ms/step - loss: 2.0927 - accuracy: 0.2692 - val_loss: 2.1918 - val_accuracy: 0.2130\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 2s 183ms/step - loss: 2.2937 - accuracy: 0.1553 - val_loss: 2.3344 - val_accuracy: 0.1126\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 2.2736 - accuracy: 0.1643 - val_loss: 2.3044 - val_accuracy: 0.1260\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 92ms/step - loss: 2.2356 - accuracy: 0.2042 - val_loss: 2.2773 - val_accuracy: 0.1392\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 102ms/step - loss: 2.2005 - accuracy: 0.1970 - val_loss: 2.2483 - val_accuracy: 0.1538\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 104ms/step - loss: 2.1622 - accuracy: 0.2278 - val_loss: 2.2234 - val_accuracy: 0.1694\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 95ms/step - loss: 2.1394 - accuracy: 0.2439 - val_loss: 2.2018 - val_accuracy: 0.1872\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 2.0743 - accuracy: 0.3053 - val_loss: 2.1794 - val_accuracy: 0.1970\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 2.0995 - accuracy: 0.2921 - val_loss: 2.1582 - val_accuracy: 0.2094\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 86ms/step - loss: 2.0853 - accuracy: 0.2914 - val_loss: 2.1380 - val_accuracy: 0.2178\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 2.0270 - accuracy: 0.3082 - val_loss: 2.1181 - val_accuracy: 0.2316\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 2s 90ms/step - loss: 2.5672 - accuracy: 0.0738 - val_loss: 2.5066 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 2.5082 - accuracy: 0.0769 - val_loss: 2.4334 - val_accuracy: 0.1126\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 2.4012 - accuracy: 0.1041 - val_loss: 2.3695 - val_accuracy: 0.1264\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 2.3290 - accuracy: 0.1232 - val_loss: 2.3102 - val_accuracy: 0.1462\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 2.2692 - accuracy: 0.1499 - val_loss: 2.2575 - val_accuracy: 0.1668\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 1s 44ms/step - loss: 2.2288 - accuracy: 0.1670 - val_loss: 2.2083 - val_accuracy: 0.1854\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 2.1616 - accuracy: 0.2212 - val_loss: 2.1615 - val_accuracy: 0.2052\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 2.0986 - accuracy: 0.2657 - val_loss: 2.1160 - val_accuracy: 0.2320\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 2.0993 - accuracy: 0.2518 - val_loss: 2.0735 - val_accuracy: 0.2508\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 2.0232 - accuracy: 0.2963 - val_loss: 2.0329 - val_accuracy: 0.2792\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 2s 49ms/step - loss: 2.3969 - accuracy: 0.1278 - val_loss: 2.2602 - val_accuracy: 0.1362\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.2548 - accuracy: 0.1503 - val_loss: 2.1440 - val_accuracy: 0.1984\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.1239 - accuracy: 0.2309 - val_loss: 2.0573 - val_accuracy: 0.2778\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.0640 - accuracy: 0.2631 - val_loss: 1.9835 - val_accuracy: 0.3438\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.9528 - accuracy: 0.3523 - val_loss: 1.9178 - val_accuracy: 0.3874\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.8852 - accuracy: 0.4090 - val_loss: 1.8573 - val_accuracy: 0.4250\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.8324 - accuracy: 0.4349 - val_loss: 1.8013 - val_accuracy: 0.4598\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.7737 - accuracy: 0.4556 - val_loss: 1.7495 - val_accuracy: 0.4914\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.7193 - accuracy: 0.5245 - val_loss: 1.7016 - val_accuracy: 0.5138\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.6260 - accuracy: 0.5534 - val_loss: 1.6571 - val_accuracy: 0.5298\n",
            "Epoch 1/10\n",
            "50/50 [==============================] - 2s 25ms/step - loss: 2.3270 - accuracy: 0.1263 - val_loss: 2.1168 - val_accuracy: 0.2012\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 2.1041 - accuracy: 0.2058 - val_loss: 1.9656 - val_accuracy: 0.2790\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 1s 14ms/step - loss: 1.9417 - accuracy: 0.3108 - val_loss: 1.8498 - val_accuracy: 0.3888\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 1.8191 - accuracy: 0.4347 - val_loss: 1.7549 - val_accuracy: 0.4330\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 1s 14ms/step - loss: 1.7472 - accuracy: 0.4413 - val_loss: 1.6737 - val_accuracy: 0.4714\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 1s 14ms/step - loss: 1.6683 - accuracy: 0.4691 - val_loss: 1.6030 - val_accuracy: 0.5072\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 1.5982 - accuracy: 0.5050 - val_loss: 1.5388 - val_accuracy: 0.5430\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 1s 14ms/step - loss: 1.5400 - accuracy: 0.5316 - val_loss: 1.4818 - val_accuracy: 0.5658\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 1.4666 - accuracy: 0.5628 - val_loss: 1.4304 - val_accuracy: 0.5800\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 1s 14ms/step - loss: 1.4385 - accuracy: 0.5657 - val_loss: 1.3829 - val_accuracy: 0.6004\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 3s 15ms/step - loss: 2.3480 - accuracy: 0.1124 - val_loss: 2.0144 - val_accuracy: 0.3268\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9735 - accuracy: 0.3591 - val_loss: 1.7719 - val_accuracy: 0.5270\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7375 - accuracy: 0.5246 - val_loss: 1.5872 - val_accuracy: 0.6160\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5651 - accuracy: 0.5917 - val_loss: 1.4421 - val_accuracy: 0.6480\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4194 - accuracy: 0.6428 - val_loss: 1.3272 - val_accuracy: 0.6634\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3271 - accuracy: 0.6432 - val_loss: 1.2346 - val_accuracy: 0.6764\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.2197 - accuracy: 0.6872 - val_loss: 1.1626 - val_accuracy: 0.6860\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.1495 - accuracy: 0.6915 - val_loss: 1.1001 - val_accuracy: 0.6946\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1047 - accuracy: 0.6784 - val_loss: 1.0503 - val_accuracy: 0.6978\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.0399 - accuracy: 0.6965 - val_loss: 1.0089 - val_accuracy: 0.7084\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 2.2437 - accuracy: 0.2509 - val_loss: 1.7764 - val_accuracy: 0.4876\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 1.7013 - accuracy: 0.5364 - val_loss: 1.4808 - val_accuracy: 0.6162\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 1.4095 - accuracy: 0.6350 - val_loss: 1.2819 - val_accuracy: 0.6606\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 1.2306 - accuracy: 0.6742 - val_loss: 1.1360 - val_accuracy: 0.6884\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 1.1017 - accuracy: 0.6949 - val_loss: 1.0351 - val_accuracy: 0.7066\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 1.0154 - accuracy: 0.7120 - val_loss: 0.9617 - val_accuracy: 0.7208\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.9442 - accuracy: 0.7356 - val_loss: 0.9056 - val_accuracy: 0.7316\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.8988 - accuracy: 0.7331 - val_loss: 0.8628 - val_accuracy: 0.7302\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.8491 - accuracy: 0.7413 - val_loss: 0.8297 - val_accuracy: 0.7446\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.8304 - accuracy: 0.7426 - val_loss: 0.7979 - val_accuracy: 0.7496\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 4s 7ms/step - loss: 2.0866 - accuracy: 0.2725 - val_loss: 1.4843 - val_accuracy: 0.6182\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 1.3864 - accuracy: 0.6353 - val_loss: 1.1350 - val_accuracy: 0.6796\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 1.0980 - accuracy: 0.6840 - val_loss: 0.9598 - val_accuracy: 0.7138\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.9413 - accuracy: 0.7092 - val_loss: 0.8606 - val_accuracy: 0.7334\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.8493 - accuracy: 0.7349 - val_loss: 0.7968 - val_accuracy: 0.7458\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.7922 - accuracy: 0.7426 - val_loss: 0.7523 - val_accuracy: 0.7550\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.7462 - accuracy: 0.7594 - val_loss: 0.7174 - val_accuracy: 0.7654\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.7308 - accuracy: 0.7551 - val_loss: 0.6935 - val_accuracy: 0.7718\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.6876 - accuracy: 0.7666 - val_loss: 0.6692 - val_accuracy: 0.7762\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.6646 - accuracy: 0.7832 - val_loss: 0.6521 - val_accuracy: 0.7806\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.8873 - accuracy: 0.3543 - val_loss: 1.1587 - val_accuracy: 0.6766\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.0878 - accuracy: 0.6830 - val_loss: 0.8921 - val_accuracy: 0.7296\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.8748 - accuracy: 0.7309 - val_loss: 0.7814 - val_accuracy: 0.7510\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.7801 - accuracy: 0.7496 - val_loss: 0.7165 - val_accuracy: 0.7690\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.7191 - accuracy: 0.7665 - val_loss: 0.6745 - val_accuracy: 0.7800\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.6869 - accuracy: 0.7737 - val_loss: 0.6401 - val_accuracy: 0.7816\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.6548 - accuracy: 0.7846 - val_loss: 0.6139 - val_accuracy: 0.7930\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.6264 - accuracy: 0.7971 - val_loss: 0.5951 - val_accuracy: 0.7998\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.5934 - accuracy: 0.8048 - val_loss: 0.5770 - val_accuracy: 0.8036\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.5838 - accuracy: 0.8086 - val_loss: 0.5656 - val_accuracy: 0.8080\n",
            "Epoch 1/10\n",
            "1600/1600 [==============================] - 9s 5ms/step - loss: 1.6454 - accuracy: 0.4735 - val_loss: 0.8764 - val_accuracy: 0.7370\n",
            "Epoch 2/10\n",
            "1600/1600 [==============================] - 8s 5ms/step - loss: 0.8325 - accuracy: 0.7433 - val_loss: 0.7028 - val_accuracy: 0.7754\n",
            "Epoch 3/10\n",
            "1600/1600 [==============================] - 8s 5ms/step - loss: 0.7040 - accuracy: 0.7706 - val_loss: 0.6326 - val_accuracy: 0.7882\n",
            "Epoch 4/10\n",
            "1600/1600 [==============================] - 8s 5ms/step - loss: 0.6323 - accuracy: 0.7932 - val_loss: 0.5874 - val_accuracy: 0.8028\n",
            "Epoch 5/10\n",
            "1600/1600 [==============================] - 8s 5ms/step - loss: 0.5953 - accuracy: 0.8021 - val_loss: 0.5585 - val_accuracy: 0.8126\n",
            "Epoch 6/10\n",
            "1600/1600 [==============================] - 8s 5ms/step - loss: 0.5653 - accuracy: 0.8124 - val_loss: 0.5381 - val_accuracy: 0.8156\n",
            "Epoch 7/10\n",
            "1600/1600 [==============================] - 8s 5ms/step - loss: 0.5380 - accuracy: 0.8197 - val_loss: 0.5193 - val_accuracy: 0.8206\n",
            "Epoch 8/10\n",
            "1600/1600 [==============================] - 8s 5ms/step - loss: 0.5275 - accuracy: 0.8200 - val_loss: 0.5061 - val_accuracy: 0.8238\n",
            "Epoch 9/10\n",
            "1600/1600 [==============================] - 8s 5ms/step - loss: 0.5084 - accuracy: 0.8295 - val_loss: 0.4963 - val_accuracy: 0.8270\n",
            "Epoch 10/10\n",
            "1600/1600 [==============================] - 8s 5ms/step - loss: 0.5014 - accuracy: 0.8308 - val_loss: 0.4902 - val_accuracy: 0.8292\n"
          ]
        }
      ],
      "source": [
        "num_iterations = len(X_train)\n",
        "i=100\n",
        "benchmark =[]\n",
        "while i< num_iterations:\n",
        "    model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "    history = model.fit(X_train[:i], y_train[:i], epochs=10,validation_data=(X_valid, y_valid))\n",
        "    benchmark += [history.history[\"accuracy\"][-1]]\n",
        "    i = i*2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDjpDzrTGohh"
      },
      "source": [
        "Printing the accuracy of the model on different training sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5fqd09zGohi",
        "outputId": "716c9b25-f11d-48ef-d16b-1e8552c2f9d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAEzCAYAAAAhEjrCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi40lEQVR4nO3de5RXdb3/8ecbEEHggJqOlzHANBTvimhaBvrLu7m6HTE5pqWkRzpp2klb5/drlV38HTsmZmlo2kWTTOunJWodT6OuzAJMS0ETBXUQFSGVa1zm8/vjMzTDOMAXmP3d8/3O87HWrJnv/m6+vNiyePn57L0/O1JKSJKk2tOr7ACSJGnzWOKSJNUoS1ySpBpliUuSVKMscUmSapQlLklSjSqsxCPipoh4LSKeXM/7ERHXRMTsiPhzRBxcVBZJkupRkSPxHwDHb+D9E4A9W78mANcVmEWSpLpTWImnlB4CFm1gl1OBH6XsUWBIROxcVB5JkupNmefEdwVeave6uXWbJEmqQJ8Sf+/oZFuna8BGxATylDv9+/c/ZLfdduuyEC0tLfTq5fV91eCxrg6Pc3V4nKvD45z99a9/fT2ltEPH7WWWeDPQvo0bgZc72zGlNBmYDDBq1Kg0ffr0LgvR1NTEmDFjuuzztH4e6+rwOFeHx7k6PM5ZRLzQ2fYy//fmbuDM1qvUDwfeTCnNLzGPJEk1pbCReETcBowB3hERzcCXgK0AUkrXA1OBE4HZwDLg7KKySJJUjwor8ZTS6Rt5PwEXFPX7S5JU78o8Jy5JUlWsWrWK5uZmVqxYUXaUDerXrx+NjY1stdVWFe1viUuS6l5zczODBg1i2LBhRHR2c1T5UkosXLiQ5uZmhg8fXtGv8bp9SVLdW7FiBdtvv323LXCAiGD77bffpNkCS1yS1CN05wJfa1MzWuKSJFXJfffdx4gRI9hjjz244oortvjzLHFJkqpgzZo1XHDBBdx7773MnDmT2267jZkzZ27RZ1rikiRVwR//+Ef22GMPdt99d/r27cu4ceO46667tugzLXFJkqpg3rx5tH/2R2NjI/Pmzduiz/QWM0lSz3LhhfD44137mQceCFdfvcFd8hpn69rSi+0ciUuSVAWNjY289FLbE7ibm5vZZZddtugzHYlLknqWjYyYi3LooYfy7LPPMmfOHHbddVemTJnCT37yky36TEtckqQq6NOnD9deey3HHXcca9as4ZOf/CT77LPPln1mF2WTJEkbceKJJ3LiiSd22ed5TlySpBpliUuSVKMscUmSapQlLknqETq7T7u72dSMlrgkqe7169ePhQsXdusiX/s88X79+lX8a7w6XZJU9xobG2lubmbBggVlR9mgfv360djYWPH+lrgkqe5ttdVWDB8+vOwYXc7pdEmSapQlLklSjbLEJUmqUZa4JEk1yhKXJKlGWeKSJNUoS1ySpBpliUuSVKMscUmSapQlLklSjbLEJUmqUZa4JEk1yhKXJKlGWeKSJNUoS1ySpBpliUuSVKMscUmSapQlLklSjbLEJUmqUZa4JEldaenSqv1Wfar2O0mSVC+WLIHZs+HZZ/NX+59fey2/v802hcewxCVJ6szSpbmc2xf02sKeP3/dfXfeGfbYA046CfbcE9asqUpES1yS1HMtWwbPPff2kn72WXj55XX3bWjIBX388fn7Hnu0fR84sJT4lrgkqb4tX75uUbcfWc+bt+6+O+6Yi/nYY9tKem1RDxpUTv4NsMQlSbVvxYq2ou44/d3cvO6+O+yQS/mYY9Yt6T32gMGDy8m/mSxxSVJt+Pvfc1F3do76pZcgpbZ9t98+l/PYsW8fUQ8ZUtofoasVWuIRcTwwCegN3JhSuqLD+4OBW4B3tmb5Zkrp5iIzSZK6sZTglVfgqadg5kz2fOAB+NrXclm/+OK6Rb3ddrmY3/e+tpJeW9Tbblven6GKCivxiOgNfAf4ANAMTIuIu1NKM9vtdgEwM6V0SkTsADwTEbemlFYWlUuS1A2klC8cmzkzf7WWNk89BW+88Y/ddhw4EPbeG448Es46a91R9XbblRa/uyhyJD4amJ1Seh4gIqYApwLtSzwBgyIigIHAImB1gZkkSdWUUr54rGNRz5wJb77Ztt9228E++8C4cTByZP555Eh+N2sWY8aOLS9/Nxep/dREV35wxEeB41NK57S+/hfgsJTSxHb7DALuBvYCBgGnpZTu6eSzJgATABoaGg6ZMmVKl+VcsmQJA0u6NaCn8VhXh8e5OjzOHaTE1gsWMGDuXLaZOzd/f+EFBrzwAn3arWC2cvBglg0bxtKhQ1k6bNg/fl617bYQ8baP9ThnY8eOnZFSGtVxe5Ej8bf/18gj7/aOAx4HjgbeBfwmIh5OKb21zi9KaTIwGWDUqFFpzJgxXRayqamJrvw8rZ/Hujo8ztXRY49zSvncdMeR9axZsHhx23477phH1GPG/GNUzT770HeHHegLDKnwt+uxx7lCRZZ4M7Bbu9eNQIc75zkbuCLl6YDZETGHPCr/Y4G5JEkb09KSy7rjFPisWXlJ0bUaGnJBf+IT60yD8453lJe9BymyxKcBe0bEcGAeMA74eId9XgSOAR6OiAZgBPB8gZkkSe21tMDcuesW9dqybv8gj512ygV99tltRT1yZL6VS6UprMRTSqsjYiJwP/kWs5tSSk9FxHmt718PXA78ICL+Qp5+/0JK6fWiMklSj9XSAnPmdD4Nvnx523677JLL+Zxz2op65EivBO+mCr1PPKU0FZjaYdv17X5+GTi2yAyS1OO8+ir85S/rfs2cmdcJX2vXXfOI+tOfbpsG33vvHnN/db1wxTZJqlVLl+bRdMfCXrCgbZ8ddoD99oNzz4V9922bCq+x5UXVOUtckrq71avz0qIdy/r559tWMNtmm1zQp5ySy3q//fJXQ0O52VUoS1ySuouU8nOqO5sK//vf8z69euXVyg46CM48s62shw+H3r3Lza+qs8QlqQyLF8OTT769sBctattn551zQU+c2FbWe+8N/fuXl1vdiiUuSUVatQqeeebthT13bts+AwfmKfCPfKStrPfbz9u3tFGWuCR1hZTy4zA7jqyffjoXOUCfPjBiBBx+eL6Fa21ZDx2ap8mlTWSJS9KmWrqUwX/+cz5Xvbasn3xy3Qd67LZbLugTT2wr6xEjYOuty8utumOJS1IlVq+G3/wGbr0VfvELDlp7z/XgwbmgP/7xtrLed18YMqTUuOoZLHFJWp+UYNq0XNxTpsBrr+XFUMaP58/DhrH/+PHQ2Njp07ekarDEJamj557LxX3LLfDss3kK/JRT4Iwz4IQTYOutWdTUlKfMpRJZ4pIEeZWz22/Pxf3oo3l0PWYMXHopfPjDTo+rW7LEJfVcy5bB3Xfn4r7//nzee//94T//E04/PU+VS92YJS6pZ1m9Gv7nf/J0+c9/np+N3dgIF1+cp8v326/shFLFLHFJ9S8leOyxXNy33QavvJKvKh83Lhf3UUd5n7ZqkiUuqX7NmQM/+UmeLn/6aejbF046CcaPz/dv9+tXdkJpi1jikurLwoX5ArVbb4Xf/S5vO+oo+Nzn4KMf9XnZqiuWuKTat3w5/PKXubjvvTcvczpyJHzjG/kCtaFDy04oFcISl1Sb1qyBpqZc3HfckZ8Ktssu8NnP5vPcBxzgIiyqe5a4pNqREjzxRD7Hfdtt8PLLMGhQniYfPx7e/36fqa0exRKX1P298EK+QO3WW+Gpp/LTwE48MRf3ySf7fG31WJa4pO7pb3+Dn/0sF/dDD+VtRx4J110HH/uYz9qWsMQldScrVsA99+TivuceWLkS9toLvvrV/JSw4cPLTih1K5a4pHK1tOSR9i235AvU3nwTdtoJLrggX6B28MFeoCathyUuqTyPPALnngszZ8LAgflBI+PHw9FHe4GaVAFLXFL1LV4MX/wifOc7+XGeP/5xLvBttik7mVRTLHFJ1XXvvfDpT0NzM0ycCF/7Wr5NTNImc8V/SdXx+utta5YPHJiXRL3mGgtc2gKWuKRipZTv8d5777ym+Ze+BH/6E7znPWUnk2qe0+mSivPii3D++TB1Khx2GNx4I+y7b9mppLrhSFxS12tpgWuvhX32yeubX311nj63wKUu5UhcUteaNQvOOSffPnbssfC978GwYWWnkuqSI3FJXWPlSrj8cjjwQHj6afjhD+G++yxwqUCOxCVtuT/+MY++//IXOO00mDQJGhrKTiXVPUfikjbf0qXwuc/lK80XLYK774YpUyxwqUociUvaPL/5TV60Zc4cOO88uOIKGDy47FRSj+JIXNKmWbQIzjorX7S21Vbw4IP58aAWuFR1lrikyqSUn++99975iWNf/CI88QQcdVTZyaQey+l0SRs3b15+NOhdd8Ehh8Cvfw0HHFB2KqnHcyQuaf1aWvJ93iNH5uK+8kp49FELXOomHIlL6txf/woTJuRz3mPHwg03wLveVXYqSe04Epe0rlWr8pXm++8Pjz+e1zt/4AELXOqGHIlLavPYY/CpT+Xy/vCH8/rnO+9cdipJ6+FIXBIsWwZf+AKMHg2vvAJ33pm/LHCpW3MkLvV0v/0tnHsuPPdcXjr1yithyJCyU0mqgCNxqad6441c3kcfne8Bf+CBfPGaBS7VjEJLPCKOj4hnImJ2RFy6nn3GRMTjEfFURDxYZB5JrX7xi3zb2E03wec/nx9ccvTRZaeStIkKm06PiN7Ad4APAM3AtIi4O6U0s90+Q4DvAsenlF6MiB2LyiOJfL574sR8vvuAA+CXv8yLt0iqSUWOxEcDs1NKz6eUVgJTgFM77PNx4OcppRcBUkqvFZhH6rlSyqPuvfeGX/0Kvv51mDbNApdqXJElvivwUrvXza3b2ns3sG1ENEXEjIg4s8A8Us/0/PPwgQ/kW8f22y+vd37ZZfnhJZJqWpFXp0cn21Inv/8hwDFAf+D3EfFoSumv63xQxARgAkBDQwNNTU1dFnLJkiVd+nlaP491daw9zrFmDbveeSfDb7qJ1Ls3z190ES+ffDLMn5+/tEX8+1wdHucNK7LEm4Hd2r1uBF7uZJ/XU0pLgaUR8RBwALBOiaeUJgOTAUaNGpXGjBnTZSGbmproys/T+nmsq6OpqYkx222XR97Tp8Mpp8B3v8u7Gxt5d9nh6oh/n6vD47xhRU6nTwP2jIjhEdEXGAfc3WGfu4D3RUSfiNgGOAyYVWAmqb6tWMHwG2/M57pffBF++tP85LHGxrKTSSpAYSPxlNLqiJgI3A/0Bm5KKT0VEee1vn99SmlWRNwH/BloAW5MKT1ZVCap7vz97/CnP8Ejj8Dvfw8PP8zQV1+FM8+Eq66C7bcvO6GkAhW6YltKaSowtcO26zu8vhK4ssgcUt149dVc1o88kr+mT89FDjB8OBxzDE8cdBAHXHJJuTklVYXLrkrd1Zo18OSTbYX9+9/npVEB+vbNU+YTJ8IRR8B73vOPdc7/5kVAUo+x0RKPiJOBqSmllirkkXquN96AP/yhrbQffRSWLMnvNTTAkUfC+efnwj74YOjXr9S4kspXyUh8HDApIu4Ebk4peeGZtKVSgmefbSvsRx6BmTPz9l698rO8zzwzj7KPOAKGDYPo7K5NST3ZRks8pTQ+Iv4JOB24OSIScDNwW0ppcdEBpbqwbFk+f92+tBcuzO8NGZJH1+PG5cI+9FAYNKjUuJJqQ0XnxFNKb7WOxPsDFwIfAj4fEdeklL5dYD6pNr300rqF/fjjsHp1fm/ECPjgB9tG2XvtlUffkrSJKjknfgrwSeBdwI+B0Sml11rv654FWOLq2VauzCW99uKzRx6B5ub83jbbwOjR8O//ngv78MO97UtSl6lkJP4x4FsppYfab0wpLYuITxYTS+rGFixY9zavadNgxYr83tCh8N73to2y99/fNcolFaaSEv8S8I+FliOiP9CQUpqbUnqgsGRSd7BmTb7grP1tXs8+m9/baqt8lfj557fd5rVrx2f8SFJxKinxnwFHtHu9pnXboYUkkrqDVavy2uN33QVvvZW37bBDvs3rnHNyaR9yCPTvX25OST1aJSXep/V54ACklFa2roUu1a+vfx1+/GM46yw4+uhc2rvv7m1ekrqVSkp8QUR8MKV0N0BEnAq8XmwsqUTTp8Pll8P48XDzzWWnkaT1qqTEzwNujYhryc8Ifwk4s9BUUlmWL8+LrOy0E3zbGy8kdW+VLPbyHHB4RAwEwgVeVNf+4z9g1iy4//68CIskdWMVLfYSEScB+wD9ovWcYErpKwXmkqrvwQfhW9/KV5sfe2zZaSRpoza6TFREXA+cBnyGPJ3+MWBowbmk6lq8OF/EtvvucKVPxpVUGypZ6/GIlNKZwN9SSl8G3gPsVmwsqcouvhheeAF++EMYMKDsNJJUkUpKvHUpKpZFxC7AKmB4cZGkKps6FW64IS+NeuSRZaeRpIpVck78lxExBLgSeAxIwA1FhpKqZuHCvHjLfvvBl79cdhpJ2iQbLPGI6AU8kFJ6A7gzIn4F9EspvVmNcFLhLrgAXn89j8a33rrsNJK0STY4nZ5SagH+q93rv1vgqhs//Wn++tKX4MADy04jSZusknPiv46Ij0S43qTqyPz58K//CocdBl/4QtlpJGmzVHJO/HPAAGB1RKwg32aWUkr/VGgyqSgp5fPgy5fnq9H7VLRcgiR1O5Ws2DaoGkGkqvn+9/M58EmTYMSIstNI0mbbaIlHxFGdbU8pPdT1caSCzZkDF10EY8fCxIllp5GkLVLJPOLn2/3cDxgNzACOLiSRVJSWFjj7bOjVC37wg/xdkmpYJdPpp7R/HRG7Af9ZWCKpKJMm5fXRb74Z3vnOstNI0hbbnKFIM7BvVweRCjVzJlx2GXzwg/CJT5SdRpK6RCXnxL9NXqUNcukfCDxRYCapa61alZ8RPmgQTJ4M3i0pqU5Uck58erufVwO3pZR+V1Aeqet9/eswYwbccQc0NJSdRpK6TCUlfgewIqW0BiAiekfENimlZcVGk7rAjBnw1a/CGWfARz5SdhpJ6lKVnBN/AOjf7nV/4L+LiSN1oRUr8jR6QwN8+9tlp5GkLlfJSLxfSmnJ2hcppSURsU2BmaSu8R//kS9ou+8+2HbbstNIUperZCS+NCIOXvsiIg4BlhcXSeoCDz0EV10F558Pxx1XdhpJKkQlI/ELgZ9FxMutr3cGTisskbSlFi+Gs86C3XeHK68sO40kFaaSxV6mRcRewAjyw0+eTimtKjyZtLkuvhjmzoWHH4YBA8pOI0mF2eh0ekRcAAxIKT2ZUvoLMDAi/rX4aNJmmDoVbrgBPv95OPLIstNIUqEqOSd+bkrpjbUvUkp/A84tLJG0uRYtyo8Y3Xdf+MpXyk4jSYWr5Jx4r4iIlFKCfJ840LfYWNJmuOACWLAA7rkHtt667DSSVLhKSvx+4PaIuJ68/Op5wL2FppI21e23w5QpcPnlcNBBZaeRpKqopMS/AEwAzidf2PYn8hXqUvcwf36+lWz0aLj00rLTSFLVbPSceEqpBXgUeB4YBRwDzCo4l1SZlODcc2HZMvjRj6BPJf9fKkn1Yb3/4kXEu4FxwOnAQuCnACmlsdWJJlXg+9/P58AnTYIRI8pOI0lVtaFhy9PAw8ApKaXZABFxUVVSSZWYMwcuugjGjoWJE8tOI0lVt6Hp9I8ArwC/jYgbIuIY8jlxqXwtLXD22fnZ4DffDL0quVtSkurLev/lSyn9IqV0GrAX0ARcBDRExHURcWyV8kmdmzQJHnwwfx86tOw0klSKSi5sW5pSujWldDLQCDwOVHQJcEQcHxHPRMTsiFjvr4mIQyNiTUR8tNLg6sFmzYLLLoNTTslrpEtSD7VJc5AppUUppe+llI7e2L6ti8J8BzgBGAmcHhEj17Pf/yXfjy5t2KpV+RnhAwfC5Ml5Ol2SeqgiTySOBmanlJ5PKa0EpgCndrLfZ4A7gdcKzKJ68Y1vwPTpcP31sNNOZaeRpFIVWeK7Ai+1e93cuu0fImJX4EPA9QXmUL2YMSOvyHbGGfBRz7xIUpErY3Q2z5k6vL4a+EJKaU1sYFo0IiaQV42joaGBpqamLooIS5Ys6dLP0/ptybHutXIlh0yYQJ8hQ5h22mms9r/Zevl3ujo8ztXhcd6wIku8Gdit3etG4OUO+4wCprQW+DuAEyNidUrp/7XfKaU0GZgMMGrUqDRmzJguC9nU1ERXfp7Wb4uO9SWXwAsvwH338d7jjuvSXPXGv9PV4XGuDo/zhhVZ4tOAPSNiODCPvPrbx9vvkFIavvbniPgB8KuOBS7x0ENw1VVw3nlggUvSPxRW4iml1RExkXzVeW/gppTSUxFxXuv7ngfXxi1enG8jGz4crryy7DSS1K0U+rSIlNJUYGqHbZ2Wd0rprCKzqEZdcgnMnZtH4wMHlp1GkroV16pU93Xvvfle8Esugfe+t+w0ktTtWOLqnhYtgk99CvbZB77ylbLTSFK35MOX1T1NnAgLFuTHjPbrV3YaSeqWLHF1P7ffDrfdlhd2OeigstNIUrfldLq6l/nz4fzzYfRouLSi5+xIUo9liav7SAnOPReWLYMf/hD6OFEkSRviv5LqPm66KZ8Dv/pq2GuvstNIUrfnSFzdw9y5cOGFMHYsfOYzZaeRpJpgiat8LS15VbYIuPlm6OVfS0mqhNPpKt8118CDD8L3vw9Dh5adRpJqhkMelWvWLLjsMjj5ZDj77LLTSFJNscRVnlWr4MwzYcAAuOGGPJ0uSaqY0+kqzze+AdOnw89+BjvtVHYaSao5jsRVjhkz8opsH/84fPSjZaeRpJpkiav6VqzI0+g77gjXXlt2GkmqWU6nq/r+9/+GmTPzo0a33bbsNJJUsxyJq7oefhj+67/g05+G448vO40k1TRLXFXTe/nyvKjL8OHwzW+WHUeSap7T6aqad113HcyZkxd2GTiw7DiSVPMcias67r2XXX75S7jkEnjf+8pOI0l1wZG4Nk1LCyxeDG++CW+8se73zrat/T5zJkuHDWPAV75SanxJqieWeE+SUr69q9Li7WzbW2/lz9mQ/v1h8GAYMiR/HzwYTjmFp447jtH9+hX8h5SknsMSr0Xz58Mrr2xeGa9cueHP7tWrrXzXfh8+/O3b2hd0x219+3b60cuamrrmzy9JAizx2pESPPBAvj3rvvvWv9+AAeuW6g47wB57VF7CAwa4hrkk1QhLvLtbtQp++tN8S9YTT0BDA3z5y7D//m8v4cGDoY//SSWpp/Bf/O7qzTdh8mSYNAnmzYORI/Pzts84A7beuux0kqRuwBLvbl58MRf3DTfkq8CPPjr/fPzxTnNLktZhiXcXM2bk8923355fjxsHF18MBx1Ubi5JUrdliZeppSU/BOSb34SmJhg0CC68EP7t3+Cd7yw7nSSpm7PEy7BiBdx6ax55z5oFjY25yM85J1+cJklSBSzxalq4EK67Lj9D+9VX4cAD4ZZb4J//Gbbaqux0kqQaY4lXw3PPwbe+BTfdBMuXwwkn5DXEx471YjVJ0mazxIv0+9/nafJf/CKPtMePh899DvbZp+xkkqQ6YIl3tTVr4K678vnuRx6BbbeFyy6DiRNh553LTidJqiOWeFdZtgx+8AO46qo8fT58OHz723D22XkpU0mSupglvqVefTVfqPbd78KiRXDYYXDFFfChD0Hv3mWnkyTVMUt8c82alUfdP/5xfjLYqafmi9WOOMKL1SRJVWGJb4qU4MEH88Vq99wD/frBJz8JF10Ee+5ZdjpJUg9jiVdi1Sq4445c3o89lh/v+eUvw/nn558lSSqBJb4hixfDjTfC1VfnB5OMGJGfLDZ+PPTvX3Y6SVIPZ4l3prkZrrkGvvc9eOsteP/788VrJ50EvXqVnU6SJMASX9fjj+f7u6dMyQ8n+djH8pPEDj207GSSJL2NJZ4S3H9/Pt/93/+d7+meOBE++1kYNqzsdJIkrVfPLvE//IFRn/oUzJmTV1O74gqYMCGvsiZJUjfXs0u8oYHUp09eae3006Fv37ITSZJUsZ5d4sOGMWPyZMaMGVN2EkmSNlmhl1pHxPER8UxEzI6ISzt5/4yI+HPr1yMRcUCReSRJqieFlXhE9Aa+A5wAjAROj4iRHXabA7w/pbQ/cDkwuag8kiTVmyJH4qOB2Sml51NKK4EpwKntd0gpPZJS+lvry0eBxgLzSJJUV4o8J74r8FK7183AYRvY/1PAvZ29ERETgAkADQ0NNDU1dVFEWLJkSZd+ntbPY10dHufq8DhXh8d5w4os8c4e5ZU63TFiLLnE39vZ+ymlybROtY8aNSp15YVoTU1NXthWJR7r6vA4V4fHuTo8zhtWZIk3A7u1e90IvNxxp4jYH7gROCGltLDAPJIk1ZUiz4lPA/aMiOER0RcYB9zdfoeIeCfwc+BfUkp/LTCLJEl1p7CReEppdURMBO4HegM3pZSeiojzWt+/Hvg/wPbAdyMCYHVKaVRRmSRJqieFLvaSUpoKTO2w7fp2P58DnFNkBkmS6pXP1ZQkqUZZ4pIk1ShLXJKkGmWJS5JUoyxxSZJqlCUuSVKNssQlSapRlrgkSTXKEpckqUZZ4pIk1ShLXJKkGmWJS5JUoyxxSZJqlCUuSVKNssQlSapRlrgkSTXKEpckqUZZ4pIk1ShLXJKkGmWJS5JUoyxxSZJqlCUuSVKNssQlSapRlrgkSTXKEpckqUZZ4pIk1ShLXJKkGmWJS5JUoyxxSZJqlCUuSVKNssQlSapRlrgkSTXKEpckqUZZ4pIk1ShLXJKkGmWJS5JUoyxxSZJqlCUuSVKNssQlSapRlrgkSTXKEpckqUZZ4pIk1ShLXJKkGmWJS5JUoyxxSZJqVKElHhHHR8QzETE7Ii7t5P2IiGta3/9zRBxcZB5JkupJYSUeEb2B7wAnACOB0yNiZIfdTgD2bP2aAFxXVB5JkupNkSPx0cDslNLzKaWVwBTg1A77nAr8KGWPAkMiYucCM0mSVDeKLPFdgZfavW5u3bap+0iSpE70KfCzo5NtaTP2ISImkKfbAZZExDNbmK29dwCvd+Hnaf081tXhca4Oj3N1eJyzoZ1tLLLEm4Hd2r1uBF7ejH1IKU0GJnd1QICImJ5SGlXEZ2tdHuvq8DhXh8e5OjzOG1bkdPo0YM+IGB4RfYFxwN0d9rkbOLP1KvXDgTdTSvMLzCRJUt0obCSeUlodEROB+4HewE0ppaci4rzW968HpgInArOBZcDZReWRJKneFDmdTkppKrmo22+7vt3PCbigyAwVKGSaXp3yWFeHx7k6PM7V4XHegMg9KkmSao3LrkqSVKN6dIlvbFlYbbmI2C0ifhsRsyLiqYj4bNmZ6llE9I6IP0XEr8rOUs8iYkhE3BERT7f+3X5P2ZnqUURc1PrvxpMRcVtE9Cs7U3fTY0u8wmVhteVWAxenlPYGDgcu8DgX6rPArLJD9ACTgPtSSnsBB+Ax73IRsSvwb8ColNK+5Aukx5WbqvvpsSVOZcvCagullOanlB5r/Xkx+R87V+UrQEQ0AicBN5adpZ5FxD8BRwHfB0gprUwpvVFqqPrVB+gfEX2AbehkHZGerieXuEu+VllEDAMOAv5QcpR6dTXw70BLyTnq3e7AAuDm1lMXN0bEgLJD1ZuU0jzgm8CLwHzyOiK/LjdV99OTS7yiJV/VNSJiIHAncGFK6a2y89SbiDgZeC2lNKPsLD1AH+Bg4LqU0kHAUsBrarpYRGxLnh0dDuwCDIiI8eWm6n56colXtOSrtlxEbEUu8FtTSj8vO0+dOhL4YETMJZ8aOjoibik3Ut1qBppTSmtnlO4gl7q61v8C5qSUFqSUVgE/B44oOVO305NLvJJlYbWFIiLI5w5npZSuKjtPvUopXZZSakwpDSP/Xf6flJKjlgKklF4BXoqIEa2bjgFmlhipXr0IHB4R27T+O3IMXkD4NoWu2NadrW9Z2JJj1aMjgX8B/hIRj7du+2Lran5SrfoMcGvrAOB5XDK6y6WU/hARdwCPke9y+ROu3vY2rtgmSVKN6snT6ZIk1TRLXJKkGmWJS5JUoyxxSZJqlCUuSVKNssQlSapRlrgkSTXKEpckqUb9f0I5v2a4Hxs9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "pd.DataFrame(benchmark).plot(figsize=(8, 5), color ='red')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0,1)\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN6j8o2YGohj",
        "outputId": "e1100866-0491-467f-a981-b6478652e176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "1719/1719 [==============================] - 12s 6ms/step - loss: 0.4881 - rounded_accuracy: 0.7467 - val_loss: 0.3814 - val_rounded_accuracy: 0.8464\n",
            "Epoch 2/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3722 - rounded_accuracy: 0.8553 - val_loss: 0.3561 - val_rounded_accuracy: 0.8762\n",
            "Epoch 3/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3481 - rounded_accuracy: 0.8797 - val_loss: 0.3406 - val_rounded_accuracy: 0.8859\n",
            "Epoch 4/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3356 - rounded_accuracy: 0.8897 - val_loss: 0.3294 - val_rounded_accuracy: 0.8959\n",
            "Epoch 5/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3250 - rounded_accuracy: 0.8986 - val_loss: 0.3217 - val_rounded_accuracy: 0.9022\n",
            "Epoch 6/16\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3199 - rounded_accuracy: 0.9027 - val_loss: 0.3182 - val_rounded_accuracy: 0.9040\n",
            "Epoch 7/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3161 - rounded_accuracy: 0.9055 - val_loss: 0.3157 - val_rounded_accuracy: 0.9087\n",
            "Epoch 8/16\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3126 - rounded_accuracy: 0.9081 - val_loss: 0.3170 - val_rounded_accuracy: 0.9103\n",
            "Epoch 9/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3113 - rounded_accuracy: 0.9099 - val_loss: 0.3111 - val_rounded_accuracy: 0.9106\n",
            "Epoch 10/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3081 - rounded_accuracy: 0.9123 - val_loss: 0.3104 - val_rounded_accuracy: 0.9068\n",
            "Epoch 11/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3071 - rounded_accuracy: 0.9129 - val_loss: 0.3069 - val_rounded_accuracy: 0.9147\n",
            "Epoch 12/16\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3049 - rounded_accuracy: 0.9151 - val_loss: 0.3061 - val_rounded_accuracy: 0.9168\n",
            "Epoch 13/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3037 - rounded_accuracy: 0.9154 - val_loss: 0.3046 - val_rounded_accuracy: 0.9169\n",
            "Epoch 14/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3023 - rounded_accuracy: 0.9170 - val_loss: 0.3040 - val_rounded_accuracy: 0.9188\n",
            "Epoch 15/16\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3016 - rounded_accuracy: 0.9171 - val_loss: 0.3026 - val_rounded_accuracy: 0.9173\n",
            "Epoch 16/16\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3016 - rounded_accuracy: 0.9176 - val_loss: 0.3018 - val_rounded_accuracy: 0.9195\n"
          ]
        }
      ],
      "source": [
        "def rounded_accuracy(y_true, y_pred):\n",
        "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))\n",
        "\n",
        "simple_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(30, activation=\"sigmoid\"),\n",
        "])\n",
        "simple_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "simple_ae = keras.models.Sequential([simple_encoder, simple_decoder])\n",
        "simple_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.),\n",
        "                  metrics=[rounded_accuracy])\n",
        "history = simple_ae.fit(X_train, X_train, epochs=16,\n",
        "                        validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7PQw_SXGohl"
      },
      "outputs": [],
      "source": [
        "simple_ae.save(\"AutoEncoder.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxEvRaksGohm"
      },
      "outputs": [],
      "source": [
        "model_A = keras.models.clone_model(simple_encoder)\n",
        "model_A.set_weights(simple_encoder.get_weights())\n",
        "model_A.add(keras.layers.Dense(300, activation=\"selu\", input_shape=[30]))\n",
        "for n_hidden in (100, 50, 50, 50):\n",
        "    model_A.add(keras.layers.Dense(n_hidden, activation=\"relu\"))   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nDb4OTcGohm"
      },
      "source": [
        "Now you could train model_B_on_A for task B, but since the new output\n",
        "layer was initialized randomly it will make large errors (at least during the\n",
        "first few epochs), so there will be large error gradients that may wreck the\n",
        "reused weights. To avoid this, one approach is to freeze the reused layers\n",
        "during the first few epochs, giving the new layer some time to learn\n",
        "reasonable weights. To do this, set every layerâ€™s trainable attribute to\n",
        "False and compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmvfoBkgGohn"
      },
      "outputs": [],
      "source": [
        "for layer in model_A.layers[:4]:\n",
        "    layer.trainable = False\n",
        "    # freezing the encoder layers\n",
        "\n",
        "model_A.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djRmjAAIGohn",
        "outputId": "1ff302c6-14ca-4bdd-eced-7646e0c247ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_13 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 30)                3030      \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 300)               9300      \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_168 (Dense)            (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_169 (Dense)            (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_170 (Dense)            (None, 50)                2550      \n",
            "=================================================================\n",
            "Total params: 131,080\n",
            "Trainable params: 40,250\n",
            "Non-trainable params: 90,830\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_A.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz8HO5fHGoho",
        "outputId": "553ba29c-f7cf-482f-d1c6-e6a1242a43a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 2.2677 - accuracy: 0.4594 - val_loss: 2.2630 - val_accuracy: 0.4744\n",
            "Epoch 2/8\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 2.2284 - accuracy: 0.4755 - val_loss: 2.2256 - val_accuracy: 0.4836\n",
            "Epoch 3/8\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 2.1956 - accuracy: 0.4878 - val_loss: 2.1954 - val_accuracy: 0.4920\n",
            "Epoch 4/8\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 2.1676 - accuracy: 0.4969 - val_loss: 2.1701 - val_accuracy: 0.4962\n",
            "Epoch 5/8\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 2.1441 - accuracy: 0.4997 - val_loss: 2.1495 - val_accuracy: 0.4990\n",
            "Epoch 6/8\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 2.1251 - accuracy: 0.5026 - val_loss: 2.1335 - val_accuracy: 0.4982\n",
            "Epoch 7/8\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 2.1097 - accuracy: 0.5048 - val_loss: 2.1204 - val_accuracy: 0.4982\n",
            "Epoch 8/8\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 2.0975 - accuracy: 0.5060 - val_loss: 2.1094 - val_accuracy: 0.5014\n"
          ]
        }
      ],
      "source": [
        "history = model_A.fit(X_train, y_train, epochs=8,\n",
        "                           validation_data=(X_valid, y_valid))\n",
        "\n",
        "# this only trains the newly created layers. \n",
        "# I just need to verify that the model is working correctly with its loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8wyaR0iGoho",
        "outputId": "04d70ee0-3ce1-4d10-d65e-eccc0b466b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.7847 - accuracy: 0.7972 - val_loss: 0.8031 - val_accuracy: 0.7860\n",
            "Epoch 2/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7910 - accuracy: 0.7955 - val_loss: 0.7954 - val_accuracy: 0.7868\n",
            "Epoch 3/16\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.7898 - accuracy: 0.7979 - val_loss: 0.7887 - val_accuracy: 0.7920\n",
            "Epoch 4/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7702 - accuracy: 0.8024 - val_loss: 0.7856 - val_accuracy: 0.7916\n",
            "Epoch 5/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7757 - accuracy: 0.7985 - val_loss: 0.7803 - val_accuracy: 0.7940\n",
            "Epoch 6/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7788 - accuracy: 0.7999 - val_loss: 0.7783 - val_accuracy: 0.7944\n",
            "Epoch 7/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7693 - accuracy: 0.8013 - val_loss: 0.7765 - val_accuracy: 0.7956\n",
            "Epoch 8/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7642 - accuracy: 0.8007 - val_loss: 0.7736 - val_accuracy: 0.7954\n",
            "Epoch 9/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7683 - accuracy: 0.8016 - val_loss: 0.7749 - val_accuracy: 0.7936\n",
            "Epoch 10/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7583 - accuracy: 0.8028 - val_loss: 0.7734 - val_accuracy: 0.7970\n",
            "Epoch 11/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7627 - accuracy: 0.8033 - val_loss: 0.7658 - val_accuracy: 0.7970\n",
            "Epoch 12/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7440 - accuracy: 0.8069 - val_loss: 0.7692 - val_accuracy: 0.7984\n",
            "Epoch 13/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7537 - accuracy: 0.8057 - val_loss: 0.7635 - val_accuracy: 0.7974\n",
            "Epoch 14/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7631 - accuracy: 0.8037 - val_loss: 0.7624 - val_accuracy: 0.8012\n",
            "Epoch 15/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7572 - accuracy: 0.8057 - val_loss: 0.7646 - val_accuracy: 0.8004\n",
            "Epoch 16/16\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7558 - accuracy: 0.8066 - val_loss: 0.7572 - val_accuracy: 0.8034\n"
          ]
        }
      ],
      "source": [
        "for layer in model_A.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_A.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "# model_A.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#                 optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "#                 metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "\n",
        "history = model_A.fit(X_train, y_train, epochs=16,\n",
        "                           validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "O8xK40tEGohp",
        "outputId": "417d281b-4df7-4421-d6de-822414daf68c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.6459 - sparse_categorical_accuracy: 0.7793 - val_loss: 0.4485 - val_sparse_categorical_accuracy: 0.8312\n",
            "Epoch 2/4\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3921 - sparse_categorical_accuracy: 0.8599 - val_loss: 0.3749 - val_sparse_categorical_accuracy: 0.8610\n",
            "Epoch 3/4\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3460 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.3554 - val_sparse_categorical_accuracy: 0.8716\n",
            "Epoch 4/4\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3143 - sparse_categorical_accuracy: 0.8863 - val_loss: 0.3297 - val_sparse_categorical_accuracy: 0.8844\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x141fbc4a550>"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128,activation='relu'),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=4,\n",
        "    validation_data=(X_valid, y_valid),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnB1U319Gohq"
      },
      "source": [
        "Compared to a normal neural network, it is almost as efficient. Maybe auto-encoders aren't that helpful?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7dmg7JjGohq"
      },
      "source": [
        "### Progress and notes:\n",
        "\n",
        "1) raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" % ValueError: logits and labels must have the same shape\n",
        "--------------------((None, 8) vs (None, 1))\n",
        "\n",
        "Solution: do not use a sigmoid function at the end with a single neuron. That means the model is a binary classifier which is not what we want.\n",
        "Solution_Time = 1.5 hour(s)\n",
        "\n",
        "\n",
        "2) Model is being trained from the beginning, as if it were never trained before.\n",
        "\n",
        "Solution: clone_model() does not clone weights!!! I have to not only copy the model, but also copy the weights. I used to save the model, then load it again, but I have discovered a way to copy the weights easily.\n",
        "Solution_Time = 4 hour(s)\n",
        "\n",
        "3) accuracy converges to 0.1\n",
        "\n",
        "Solution: I have to freeze the newly created layers first, or else the model will collapse, or get stuck on a local minimum!\n",
        "Solution_Time = 1 hour(s)\n",
        "\n",
        "4) accuracy converges to 0.0000e+00 \n",
        "\n",
        "model_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                     metrics=[\"accuracy\"])\n",
        "                     \n",
        "Solution: it seems using the binary_crossentropy as a loss function makes the model the worst. I thought since it is a classification problem binary crossentropy would not ne a problem. But for some reason, it is !?\n",
        "Solution_Time = 3 hour(s)\n",
        "\n",
        "5) low performance : stuck at 50%, then 60%. Now stuck at 80%.\n",
        "\n",
        "Solution: First, I tried freezing layer per layer, until I eventually froze all transfered layers as this step made the performance go from 50% to 60% accuracy. Then I tried to change the learning rate from the compilation with frozen layers to the compilation of all layers. This has pushed the performance from 60% to 80%. I tried replacing the top layer or dropping it, but performance would not really change. \n",
        "Solution_Time =  3 hour(s)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Lab8.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}